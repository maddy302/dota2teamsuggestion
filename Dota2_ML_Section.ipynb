{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This workbook is primarily to get the data from the sqlite3 db, matches table and create the train and test the models.\n",
    "There are many models implemented , uncomment the appropriate one and run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "119\n",
      "120\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn import svm\n",
    "from sklearn import neighbors\n",
    "#from sklearn.neural_network import MLPClassifier\n",
    "from sklearn import preprocessing\n",
    "import math\n",
    "import time\n",
    "\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "import simple_heroes\n",
    "\n",
    "import sqlite3\n",
    "import os\n",
    "import os.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_standard(radiant_won, radiant, dire):\n",
    "    \"\"\"\n",
    "    Turn a match constisting of its winner and the radiant and dire heroes into a feature vector.\n",
    "    \n",
    "    The default version uses a 224 dimensional feature vector and sets elements corresponding to the picked heroes to 1 while the rest are set to 0.\n",
    "    The first 112 elements are the heroes on the radiant team and the other the heroes on the dire team.\n",
    "    \n",
    "    The target class 0 represents the radiant winning, and 1 the dire winning.\n",
    "    \"\"\"\n",
    "    def put_heroes_in_features(heroes, features):\n",
    "        for i in heroes:\n",
    "            features[simple_heroes.real_to_ordered(i)] = 1.0\n",
    "\n",
    "    winner = int(not radiant_won)\n",
    "\n",
    "    radiant_heroes = [0] * len(simple_heroes.dota_hero_ids)\n",
    "    dire_heroes = [0] * len(simple_heroes.dota_hero_ids)\n",
    "\n",
    "    put_heroes_in_features(radiant, radiant_heroes)\n",
    "    put_heroes_in_features(dire, dire_heroes)\n",
    "\n",
    "    features = radiant_heroes + dire_heroes\n",
    "\n",
    "    return (winner, features)\n",
    "\n",
    "def load_data(database, undersample=True):\n",
    "    \"\"\"\n",
    "    Load data from a sqlite3 database and convert the matches into feature vectors in form of numpy arrays.\n",
    "    \n",
    "    Optionally perform undersampling to get the same number of samples of both classes.\n",
    "    \n",
    "    This method can be used directly, or indirectly via make_training_validate_test.\n",
    "    \"\"\"\n",
    "    connection = sqlite3.connect(database)\n",
    "    if undersample:\n",
    "        number_of_radiant_wins = connection.execute('SELECT COUNT(radiant_win) FROM matches WHERE radiant_win IS NOT NULL AND radiant_win = 1 AND has_leaver = 0 AND radiant_hero_1 != 0 AND radiant_hero_2 != 0 AND radiant_hero_3 != 0 AND radiant_hero_4 != 0 AND radiant_hero_5 != 0 AND dire_hero_1 != 0 AND dire_hero_2 != 0 AND dire_hero_3 != 0 AND dire_hero_4 != 0 AND dire_hero_5 != 0').fetchone()[0]\n",
    "        number_of_dire_wins = connection.execute('SELECT COUNT(radiant_win) FROM matches WHERE radiant_win IS NOT NULL AND radiant_win = 0 AND has_leaver = 0 AND radiant_hero_1 != 0 AND radiant_hero_2 != 0 AND radiant_hero_3 != 0 AND radiant_hero_4 != 0 AND radiant_hero_5 != 0 AND dire_hero_1 != 0 AND dire_hero_2 != 0 AND dire_hero_3 != 0 AND dire_hero_4 != 0 AND dire_hero_5 != 0').fetchone()[0]\n",
    "        max_games_per_class = min(number_of_radiant_wins, number_of_dire_wins)\n",
    "        radiant_wins = 0\n",
    "        dire_wins = 0\n",
    "    dataset = list()\n",
    "    targetset = list()\n",
    "    for lineno, line in enumerate(connection.execute('SELECT radiant_win, radiant_hero_1,radiant_hero_2,radiant_hero_3,radiant_hero_4,radiant_hero_5, dire_hero_1,dire_hero_2,dire_hero_3,dire_hero_4,dire_hero_5 FROM matches WHERE radiant_win IS NOT NULL AND has_leaver = 0 AND radiant_hero_1 != 0 AND radiant_hero_2 != 0 AND radiant_hero_3 != 0 AND radiant_hero_4 != 0 AND radiant_hero_5 != 0 AND dire_hero_1 != 0 AND dire_hero_2 != 0 AND dire_hero_3 != 0 AND dire_hero_4 != 0 AND dire_hero_5 != 0')):\n",
    "        radiant_won = line[0]\n",
    "\n",
    "        if undersample:\n",
    "            if radiant_wins == max_games_per_class and dire_wins == max_games_per_class: #both classes already at max games\n",
    "                break\n",
    "            elif radiant_won == 0: #dire won\n",
    "                if dire_wins == max_games_per_class: #dire already at max games\n",
    "                    continue\n",
    "                else:\n",
    "                    dire_wins += 1\n",
    "            else: #radiant won\n",
    "                if radiant_wins == max_games_per_class: #radiant already at max games\n",
    "                    continue\n",
    "                else:\n",
    "                    radiant_wins += 1\n",
    "\n",
    "        radiant_hero_ids = line[1:6]\n",
    "        dire_hero_ids  = line[6:]\n",
    "        winner, features = extract_standard(radiant_won, radiant_hero_ids, dire_hero_ids)\n",
    "        targetset.append(winner)\n",
    "        dataset.append(features)\n",
    "    connection.close()\n",
    "    \n",
    "    samples = np.array(dataset)\n",
    "    target = np.array(targetset)\n",
    "    # http://stackoverflow.com/questions/4601373/better-way-to-shuffle-two-numpy-arrays-in-unison\n",
    "    rng_state = np.random.get_state()\n",
    "    np.random.shuffle(samples)\n",
    "    np.random.set_state(rng_state)\n",
    "    np.random.shuffle(target)\n",
    "    return (samples, target)\n",
    "\n",
    "\n",
    "def make_training_validate_test(database, training_ratio, undersample=True):\n",
    "    \"\"\"\n",
    "    Create a training, validate and test set to be used in model parameter tuning.\n",
    "    \n",
    "    Specified is the amount of samples in the training set in form of a ratio. The validate and test sets use remaining samples split evenly between them.\n",
    "    \n",
    "    The results are written to disk in the data directory.\n",
    "    \"\"\"\n",
    "    assert(training_ratio > 0 and training_ratio < 1)\n",
    "    validate_ratio = test_ratio = (1-training_ratio) / 2\n",
    "    (data, target) = load_data(database, undersample=undersample)\n",
    "    \n",
    "    number_of_samples = len(target)\n",
    "    number_of_training_samples = math.floor(number_of_samples * training_ratio)\n",
    "    number_of_validate_samples = math.floor(number_of_samples * validate_ratio)\n",
    "    number_of_test_samples = math.floor(number_of_samples * test_ratio)\n",
    "    print(number_of_training_samples)\n",
    "    print('number_of_validate_samples:')\n",
    "    print(number_of_validate_samples)\n",
    "    training_data = data[0:number_of_training_samples]\n",
    "    training_target = target[0:number_of_training_samples]\n",
    "    validate_data = data[number_of_training_samples:number_of_training_samples+number_of_validate_samples]\n",
    "    validate_target = target[number_of_training_samples:number_of_training_samples+number_of_validate_samples]\n",
    "    test_data = data[number_of_training_samples+number_of_validate_samples:number_of_training_samples+number_of_validate_samples+number_of_test_samples]\n",
    "    test_target = target[number_of_training_samples+number_of_validate_samples:number_of_training_samples+number_of_validate_samples+number_of_validate_samples]\n",
    "    \n",
    "    joblib.dump(training_data, \"data/training_data\");\n",
    "    joblib.dump(training_target, \"data/training_target\");\n",
    "    joblib.dump(validate_data, \"data/validate_data\");\n",
    "    joblib.dump(validate_target, \"data/validate_target\");\n",
    "    joblib.dump(test_data, \"data/test_data\");\n",
    "    joblib.dump(test_target, \"data/test_target\");\n",
    "\n",
    "\n",
    "def export_model(model, name):\n",
    "    \"\"\"Export a model to disk. Models can consist of multiple files so a directory is created for each model.\"\"\"\n",
    "    path = \"data/{}/\".format(name)\n",
    "    filename = \"{}.model\".format(name)\n",
    "    if os.path.isdir(path):\n",
    "        print(\"model already exists\")\n",
    "        return\n",
    "    else:\n",
    "        os.mkdir(path)\n",
    "        joblib.dump(model, path + filename)\n",
    "        \n",
    "def load_model(name):\n",
    "    \"\"\"Load a model from disk.\"\"\"\n",
    "    model = joblib.load(\"data/{}/{}.model\".format(name, name))\n",
    "    # Setting n_jobs to 1 in case it was set to a higher number while training the model seems to makes predictions of single samples much faster.\n",
    "    model.n_jobs = 1\n",
    "    return model\n",
    "\n",
    "def print_speed_and_accuracy(models = [\"decisiontree\", \"gradienttreeboosting\", \"knn\", \"logisticregression\", \"randomforest\"]):\n",
    "    \"\"\"\n",
    "    Helper method to print speed and accuracy of already created models on the test data.\n",
    "    \n",
    "    Speed is measured in the time it takes to predict 1000 samples sequentially.\n",
    "    \"\"\"\n",
    "    test_data = joblib.load(\"data/test_data\")\n",
    "    test_target = joblib.load(\"data/test_target\")\n",
    "\n",
    "    for model in models:\n",
    "        model = load_model(model)\n",
    "        accuracy = model.score(test_data, test_target)\n",
    "        start = time.time()\n",
    "        for i in range(1000):\n",
    "            model.predict_proba([test_data[i]])\n",
    "        end = time.time()\n",
    "        duration = end - start\n",
    "        print(model, accuracy, duration)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10870.0\n",
      "number_of_validate_samples:\n",
      "1358.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Madhukar\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:96: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "C:\\Users\\Madhukar\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:97: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "C:\\Users\\Madhukar\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:98: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "C:\\Users\\Madhukar\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:99: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "C:\\Users\\Madhukar\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:100: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "C:\\Users\\Madhukar\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:101: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n"
     ]
    }
   ],
   "source": [
    "make_training_validate_test(\"dota2data\", 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "training_data = joblib.load(\"data/training_data\")\n",
    "training_target = joblib.load(\"data/training_target\")\n",
    "\n",
    "validate_data = joblib.load(\"data/validate_data\")\n",
    "validate_target = joblib.load(\"data/validate_target\")\n",
    "\n",
    "test_data = joblib.load(\"data/test_data\")\n",
    "test_target = joblib.load(\"data/test_target\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.63549337260677463"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "#training a model\n",
    "model = linear_model.LogisticRegression(solver='sag', dual=False, penalty='l2', n_jobs=4)\n",
    "modelname = \"logisticregression\"\n",
    "\n",
    "model.fit(training_data, training_target)\n",
    "model.score(validate_data, validate_target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#storing the model\n",
    "export_model(model, modelname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.62002945508100149"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#training a model\n",
    "model = RandomForestClassifier(n_estimators=200, min_samples_split=0.001, max_depth=None, max_features=\"auto\", n_jobs=2)\n",
    "modelname = \"random_forest_classifier\"\n",
    "\n",
    "model.fit(training_data, training_target)\n",
    "model.score(validate_data, validate_target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "export_model(model, modelname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.57363770250368185"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#training a model\n",
    "model = GradientBoostingClassifier(n_estimators=75, max_features=None, max_depth=15)\n",
    "modelname = \"gradient_Boosting_classifier\"\n",
    "\n",
    "model.fit(training_data, training_target)\n",
    "model.score(validate_data, validate_target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "export_model(model, modelname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.60382916053019142"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#training a model\n",
    "model = neighbors.KNeighborsClassifier(algorithm='ball_tree', n_neighbors=180, weights='distance', metric='manhattan', leaf_size=200, n_jobs=4)\n",
    "modelname = \"K_Neighbhors_classifier\"\n",
    "\n",
    "model.fit(training_data, training_target)\n",
    "model.score(validate_data, validate_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "export_model(model, modelname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.57731958762886593"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "model = MLPClassifier(hidden_layer_sizes=(100,))\n",
    "modelname = \"MLPCLassifier\"\n",
    "\n",
    "model.fit(training_data, training_target)\n",
    "model.score(validate_data, validate_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "export_model(model, modelname)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
