{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This workbook is primarily to get the data from the sqlite3 db, matches table and create the train and test the models.\n",
    "There are many models implemented , uncomment the appropriate one and run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn import svm\n",
    "from sklearn import neighbors\n",
    "#from sklearn.neural_network import MLPClassifier\n",
    "from sklearn import preprocessing\n",
    "import math\n",
    "import time\n",
    "\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "import simple_heroes\n",
    "\n",
    "import sqlite3\n",
    "import os\n",
    "import os.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_standard(radiant_won, radiant, dire):\n",
    "    \"\"\"\n",
    "    Turn a match constisting of its winner and the radiant and dire heroes into a feature vector.\n",
    "    \n",
    "    The default version uses a 224 dimensional feature vector and sets elements corresponding to the picked heroes to 1 while the rest are set to 0.\n",
    "    The first 112 elements are the heroes on the radiant team and the other the heroes on the dire team.\n",
    "    \n",
    "    The target class 0 represents the radiant winning, and 1 the dire winning.\n",
    "    \"\"\"\n",
    "    def put_heroes_in_features(heroes, features):\n",
    "        for i in heroes:\n",
    "            features[simple_heroes.real_to_ordered(i)] = 1.0\n",
    "\n",
    "    winner = int(not radiant_won)\n",
    "\n",
    "    radiant_heroes = [0] * len(simple_heroes.dota_hero_ids)\n",
    "    dire_heroes = [0] * len(simple_heroes.dota_hero_ids)\n",
    "\n",
    "    put_heroes_in_features(radiant, radiant_heroes)\n",
    "    put_heroes_in_features(dire, dire_heroes)\n",
    "\n",
    "    features = radiant_heroes + dire_heroes\n",
    "\n",
    "    return (winner, features)\n",
    "\n",
    "def load_data(database, undersample=True):\n",
    "    \"\"\"\n",
    "    Load data from a sqlite3 database and convert the matches into feature vectors in form of numpy arrays.\n",
    "    \n",
    "    Optionally perform undersampling to get the same number of samples of both classes.\n",
    "    \n",
    "    This method can be used directly, or indirectly via make_training_validate_test.\n",
    "    \"\"\"\n",
    "    connection = sqlite3.connect(database)\n",
    "    if undersample:\n",
    "        number_of_radiant_wins = connection.execute('SELECT COUNT(radiant_win) FROM matches WHERE radiant_win IS NOT NULL AND radiant_win = 1 AND has_leaver = 0 AND radiant_hero_1 != 0 AND radiant_hero_2 != 0 AND radiant_hero_3 != 0 AND radiant_hero_4 != 0 AND radiant_hero_5 != 0 AND dire_hero_1 != 0 AND dire_hero_2 != 0 AND dire_hero_3 != 0 AND dire_hero_4 != 0 AND dire_hero_5 != 0').fetchone()[0]\n",
    "        number_of_dire_wins = connection.execute('SELECT COUNT(radiant_win) FROM matches WHERE radiant_win IS NOT NULL AND radiant_win = 0 AND has_leaver = 0 AND radiant_hero_1 != 0 AND radiant_hero_2 != 0 AND radiant_hero_3 != 0 AND radiant_hero_4 != 0 AND radiant_hero_5 != 0 AND dire_hero_1 != 0 AND dire_hero_2 != 0 AND dire_hero_3 != 0 AND dire_hero_4 != 0 AND dire_hero_5 != 0').fetchone()[0]\n",
    "        max_games_per_class = min(number_of_radiant_wins, number_of_dire_wins)\n",
    "        radiant_wins = 0\n",
    "        dire_wins = 0\n",
    "    dataset = list()\n",
    "    targetset = list()\n",
    "    for lineno, line in enumerate(connection.execute('SELECT radiant_win, radiant_hero_1,radiant_hero_2,radiant_hero_3,radiant_hero_4,radiant_hero_5, dire_hero_1,dire_hero_2,dire_hero_3,dire_hero_4,dire_hero_5 FROM matches WHERE radiant_win IS NOT NULL AND has_leaver = 0 AND radiant_hero_1 != 0 AND radiant_hero_2 != 0 AND radiant_hero_3 != 0 AND radiant_hero_4 != 0 AND radiant_hero_5 != 0 AND dire_hero_1 != 0 AND dire_hero_2 != 0 AND dire_hero_3 != 0 AND dire_hero_4 != 0 AND dire_hero_5 != 0')):\n",
    "        radiant_won = line[0]\n",
    "\n",
    "        if undersample:\n",
    "            if radiant_wins == max_games_per_class and dire_wins == max_games_per_class: #both classes already at max games\n",
    "                break\n",
    "            elif radiant_won == 0: #dire won\n",
    "                if dire_wins == max_games_per_class: #dire already at max games\n",
    "                    continue\n",
    "                else:\n",
    "                    dire_wins += 1\n",
    "            else: #radiant won\n",
    "                if radiant_wins == max_games_per_class: #radiant already at max games\n",
    "                    continue\n",
    "                else:\n",
    "                    radiant_wins += 1\n",
    "\n",
    "        radiant_hero_ids = line[1:6]\n",
    "        dire_hero_ids  = line[6:]\n",
    "        winner, features = extract_standard(radiant_won, radiant_hero_ids, dire_hero_ids)\n",
    "        targetset.append(winner)\n",
    "        dataset.append(features)\n",
    "    connection.close()\n",
    "    \n",
    "    samples = np.array(dataset)\n",
    "    target = np.array(targetset)\n",
    "    # http://stackoverflow.com/questions/4601373/better-way-to-shuffle-two-numpy-arrays-in-unison\n",
    "    rng_state = np.random.get_state()\n",
    "    np.random.shuffle(samples)\n",
    "    np.random.set_state(rng_state)\n",
    "    np.random.shuffle(target)\n",
    "    return (samples, target)\n",
    "\n",
    "\n",
    "def make_training_validate_test(database, training_ratio, undersample=True):\n",
    "    \"\"\"\n",
    "    Create a training, validate and test set to be used in model parameter tuning.\n",
    "    \n",
    "    Specified is the amount of samples in the training set in form of a ratio. The validate and test sets use remaining samples split evenly between them.\n",
    "    \n",
    "    The results are written to disk in the data directory.\n",
    "    \"\"\"\n",
    "    assert(training_ratio > 0 and training_ratio < 1)\n",
    "    validate_ratio = test_ratio = (1-training_ratio) / 2\n",
    "    (data, target) = load_data(database, undersample=undersample)\n",
    "    \n",
    "    number_of_samples = len(target)\n",
    "    number_of_training_samples = math.floor(number_of_samples * training_ratio)\n",
    "    number_of_validate_samples = math.floor(number_of_samples * validate_ratio)\n",
    "    number_of_test_samples = math.floor(number_of_samples * test_ratio)\n",
    "    \n",
    "    training_data = data[0:number_of_training_samples]\n",
    "    training_target = target[0:number_of_training_samples]\n",
    "    validate_data = data[number_of_training_samples:number_of_training_samples+number_of_validate_samples]\n",
    "    validate_target = target[number_of_training_samples:number_of_training_samples+number_of_validate_samples]\n",
    "    test_data = data[number_of_training_samples+number_of_validate_samples:number_of_training_samples+number_of_validate_samples+number_of_test_samples]\n",
    "    test_target = target[number_of_training_samples+number_of_validate_samples:number_of_training_samples+number_of_validate_samples+number_of_validate_samples]\n",
    "    \n",
    "    joblib.dump(training_data, \"dota2data/training_data\");\n",
    "    joblib.dump(training_target, \"dota2data/training_target\");\n",
    "    joblib.dump(validate_data, \"dota2data/validate_data\");\n",
    "    joblib.dump(validate_target, \"dota2data/validate_target\");\n",
    "    joblib.dump(test_data, \"dota2data/test_data\");\n",
    "    joblib.dump(test_target, \"dota2data/test_target\");\n",
    "\n",
    "\n",
    "def export_model(model, name):\n",
    "    \"\"\"Export a model to disk. Models can consist of multiple files so a directory is created for each model.\"\"\"\n",
    "    path = \"data/{}/\".format(name)\n",
    "    filename = \"{}.model\".format(name)\n",
    "    if os.path.isdir(path):\n",
    "        print(\"model already exists\")\n",
    "        return\n",
    "    else:\n",
    "        os.mkdir(path)\n",
    "        joblib.dump(model, path + filename)\n",
    "        \n",
    "def load_model(name):\n",
    "    \"\"\"Load a model from disk.\"\"\"\n",
    "    model = joblib.load(\"data/{}/{}.model\".format(name, name))\n",
    "    # Setting n_jobs to 1 in case it was set to a higher number while training the model seems to makes predictions of single samples much faster.\n",
    "    model.n_jobs = 1\n",
    "    return model\n",
    "\n",
    "def print_speed_and_accuracy(models = [\"decisiontree\", \"gradienttreeboosting\", \"knn\", \"logisticregression\", \"randomforest\"]):\n",
    "    \"\"\"\n",
    "    Helper method to print speed and accuracy of already created models on the test data.\n",
    "    \n",
    "    Speed is measured in the time it takes to predict 1000 samples sequentially.\n",
    "    \"\"\"\n",
    "    test_data = joblib.load(\"data/test_data\")\n",
    "    test_target = joblib.load(\"data/test_target\")\n",
    "\n",
    "    for model in models:\n",
    "        model = load_model(model)\n",
    "        accuracy = model.score(test_data, test_target)\n",
    "        start = time.time()\n",
    "        for i in range(1000):\n",
    "            model.predict_proba([test_data[i]])\n",
    "        end = time.time()\n",
    "        duration = end - start\n",
    "        print(model, accuracy, duration)\n",
    "\n",
    "\n",
    "\n",
    "make_training_validate_test(\"dota2data/matches.sqlite\", 0.8)\n",
    "training_data = joblib.load(\"dota2data/training_data\")\n",
    "training_target = joblib.load(\"dota2data/training_target\")\n",
    "\n",
    "validate_data = joblib.load(\"dota2data/validate_data\")\n",
    "validate_target = joblib.load(\"dota2data/validate_target\")\n",
    "\n",
    "test_data = joblib.load(\"dota2data/test_data\")\n",
    "test_target = joblib.load(\"dota2data/test_target\")\n",
    "\n",
    "\n",
    "#training a model\n",
    "model = linear_model.LogisticRegression(solver='sag', dual=False, penalty='l2', n_jobs=4)\n",
    "modelname = \"logisticregression\"\n",
    "\n",
    "model.fit(training_data, training_target)\n",
    "model.score(validate_data, validate_target)\n",
    "\n",
    "\n",
    "#storing the model\n",
    "export_model(model, modelname)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
